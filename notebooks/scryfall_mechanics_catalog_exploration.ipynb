{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be85b269",
   "metadata": {},
   "source": [
    "# Scryfall Mechanics Catalog Exploration\n",
    "\n",
    "**Objective:** Explore and validate Scryfall's mechanics catalog endpoints (keyword abilities, keyword actions, and ability words) for MTG card scoring system integration.\n",
    "\n",
    "**Status:** Phase 0 - API Testing & Validation ONLY\n",
    "\n",
    "**Purpose:** Confirm we can reliably fetch mechanics from Scryfall before designing MongoDB schema or integrating into the scoring system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd2c9ac",
   "metadata": {},
   "source": [
    "## Setup & Dependencies\n",
    "\n",
    "Import required libraries and establish connectivity to the Scryfall API. Create a helper function to fetch catalog data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0b5318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scryfall API is reachable\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Scryfall API base URL\n",
    "SCRYFALL_API = \"https://api.scryfall.com\"\n",
    "\n",
    "# Test basic connectivity\n",
    "response = requests.get(f\"{SCRYFALL_API}/catalog/card-names\", params={'limit': 1})\n",
    "if response.status_code == 200:\n",
    "    print(\"âœ… Scryfall API is reachable\")\n",
    "else:\n",
    "    print(f\"âŒ Scryfall API error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352e1ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… fetch_catalog() helper function created\n"
     ]
    }
   ],
   "source": [
    "def fetch_catalog(catalog_name):\n",
    "    \"\"\"Fetch a Scryfall catalog by name\"\"\"\n",
    "    url = f\"{SCRYFALL_API}/catalog/{catalog_name}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'catalog_name': catalog_name,\n",
    "            'data': data.get('data', []),\n",
    "            'total_values': data.get('total_values', 0),\n",
    "            'object': data.get('object'),\n",
    "            'uri': data.get('uri')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'catalog_name': catalog_name,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"âœ… fetch_catalog() helper function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254151c",
   "metadata": {},
   "source": [
    "## Fetch Keyword Abilities Catalog\n",
    "\n",
    "Call the keyword-abilities endpoint to retrieve all keyword abilities. Display total count, sample mechanics, and verify data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bb0778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Keyword Abilities: 216 total\n",
      "\n",
      "ðŸ“Š Sample (first 20):\n",
      "  1. Living weapon\n",
      "  2. Jump-start\n",
      "  3. Commander ninjutsu\n",
      "  4. Legendary landwalk\n",
      "  5. Nonbasic landwalk\n",
      "  6. Megamorph\n",
      "  7. Haunt\n",
      "  8. Forecast\n",
      "  9. Graft\n",
      "  10. Fortify\n",
      "  11. Frenzy\n",
      "  12. Gravestorm\n",
      "  13. Hideaway\n",
      "  14. Level Up\n",
      "  15. Infect\n",
      "  16. Reach\n",
      "  17. Rampage\n",
      "  18. Phasing\n",
      "  19. Multikicker\n",
      "  20. Morph\n",
      "\n",
      "ðŸ“Š Sample (last 10):\n",
      "  - Fear\n",
      "  - Tiered\n",
      "  - Mobilize\n",
      "  - Double team\n",
      "  - Job select\n",
      "  - Mayhem\n",
      "  - Web-slinging\n",
      "  - Prowl\n",
      "  - Solved\n",
      "  - Firebending\n"
     ]
    }
   ],
   "source": [
    "# Fetch keyword abilities\n",
    "abilities_result = fetch_catalog('keyword-abilities')\n",
    "\n",
    "if abilities_result['success']:\n",
    "    abilities = abilities_result['data']\n",
    "    print(f\"âœ… Keyword Abilities: {len(abilities)} total\")\n",
    "    print(f\"\\nðŸ“Š Sample (first 20):\")\n",
    "    for i, ability in enumerate(abilities[:20], 1):\n",
    "        print(f\"  {i}. {ability}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Sample (last 10):\")\n",
    "    for ability in abilities[-10:]:\n",
    "        print(f\"  - {ability}\")\n",
    "else:\n",
    "    print(f\"âŒ Error fetching keyword abilities: {abilities_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbd1b9",
   "metadata": {},
   "source": [
    "## Fetch Keyword Actions Catalog\n",
    "\n",
    "Call the keyword-actions endpoint to retrieve all keyword actions. Display total count and sample mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a913e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Keyword Actions: 70 total\n",
      "\n",
      "ðŸ“Š Sample (first 20):\n",
      "  1. Seek\n",
      "  2. Activate\n",
      "  3. Attach\n",
      "  4. Cast\n",
      "  5. Counter\n",
      "  6. Create\n",
      "  7. Destroy\n",
      "  8. Discard\n",
      "  9. Double\n",
      "  10. Exchange\n",
      "  11. Exile\n",
      "  12. Adapt\n",
      "  13. Support\n",
      "  14. Play\n",
      "  15. Regenerate\n",
      "  16. Reveal\n",
      "  17. Sacrifice\n",
      "  18. Shuffle\n",
      "  19. Tap\n",
      "  20. Untap\n",
      "\n",
      "ðŸ“Š Sample (last 10):\n",
      "  - Plot\n",
      "  - Heist\n",
      "  - Forage\n",
      "  - Manifest dread\n",
      "  - Endure\n",
      "  - Waterbend\n",
      "  - Airbend\n",
      "  - Earthbend\n",
      "  - Blight\n",
      "  - Behold\n",
      "\n",
      "âœ… CONFIRMED: 'Proliferate' found in keyword actions\n"
     ]
    }
   ],
   "source": [
    "# Fetch keyword actions\n",
    "actions_result = fetch_catalog('keyword-actions')\n",
    "\n",
    "if actions_result['success']:\n",
    "    actions = actions_result['data']\n",
    "    print(f\"âœ… Keyword Actions: {len(actions)} total\")\n",
    "    print(f\"\\nðŸ“Š Sample (first 20):\")\n",
    "    for i, action in enumerate(actions[:20], 1):\n",
    "        print(f\"  {i}. {action}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Sample (last 10):\")\n",
    "    for action in actions[-10:]:\n",
    "        print(f\"  - {action}\")\n",
    "    \n",
    "    # Check if proliferate is included\n",
    "    if 'Proliferate' in actions or 'proliferate' in actions:\n",
    "        print(\"\\nâœ… CONFIRMED: 'Proliferate' found in keyword actions\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ WARNING: 'Proliferate' not found - check casing\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ Error fetching keyword actions: {actions_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec23f5",
   "metadata": {},
   "source": [
    "## Fetch Ability Words Catalog\n",
    "\n",
    "Call the ability-words endpoint to retrieve all ability words. Display total count and verify presence of common ability words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976ac68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ability Words: 66 total\n",
      "\n",
      "ðŸ“Š Sample (first 20):\n",
      "  1. Eerie\n",
      "  2. Battalion\n",
      "  3. Bloodrush\n",
      "  4. Channel\n",
      "  5. Chroma\n",
      "  6. Cohort\n",
      "  7. Constellation\n",
      "  8. Converge\n",
      "  9. Delirium\n",
      "  10. Domain\n",
      "  11. Fateful hour\n",
      "  12. Ferocious\n",
      "  13. Formidable\n",
      "  14. Grandeur\n",
      "  15. Hellbent\n",
      "  16. Heroic\n",
      "  17. Imprint\n",
      "  18. Inspired\n",
      "  19. Join forces\n",
      "  20. Kinship\n",
      "\n",
      "ðŸ“Š Sample (last 10):\n",
      "  - Celebration\n",
      "  - Paradox\n",
      "  - Disappear\n",
      "  - Will of the Planeswalkers\n",
      "  - Survival\n",
      "  - Flurry\n",
      "  - Valiant\n",
      "  - Start your engines!\n",
      "  - Renew\n",
      "  - Vivid\n",
      "  âœ… Landfall found\n",
      "  âœ… Raid found\n",
      "  âœ… Metalcraft found\n",
      "  âœ… Battalion found\n"
     ]
    }
   ],
   "source": [
    "# Fetch ability words\n",
    "ability_words_result = fetch_catalog('ability-words')\n",
    "\n",
    "if ability_words_result['success']:\n",
    "    ability_words = ability_words_result['data']\n",
    "    print(f\"âœ… Ability Words: {len(ability_words)} total\")\n",
    "    print(f\"\\nðŸ“Š Sample (first 20):\")\n",
    "    for i, word in enumerate(ability_words[:20], 1):\n",
    "        print(f\"  {i}. {word}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Sample (last 10):\")\n",
    "    for word in ability_words[-10:]:\n",
    "        print(f\"  - {word}\")\n",
    "    \n",
    "    # Check for common ability words\n",
    "    common_ability_words = ['Landfall', 'Raid', 'Metalcraft', 'Battalion']\n",
    "    for word in common_ability_words:\n",
    "        if word in ability_words:\n",
    "            print(f\"  âœ… {word} found\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ {word} not found\")\n",
    "            \n",
    "else:\n",
    "    print(f\"âŒ Error fetching ability words: {ability_words_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c55130",
   "metadata": {},
   "source": [
    "## Data Quality Analysis\n",
    "\n",
    "Combine all mechanics into a pandas DataFrame with computed fields and generate summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879a528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š DATA QUALITY ANALYSIS\n",
      "\n",
      "Total mechanics: 352\n",
      "\n",
      "Breakdown by category:\n",
      "category\n",
      "keyword_ability    216\n",
      "keyword_action      70\n",
      "ability_word        66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“ String length statistics:\n",
      "                 count      mean       std  min  25%  50%   75%   max\n",
      "category                                                             \n",
      "ability_word      66.0  8.893939  3.965733  4.0  6.0  8.0  10.0  25.0\n",
      "keyword_ability  216.0  8.310185  3.158022  4.0  6.0  8.0  10.0  23.0\n",
      "keyword_action    70.0  7.742857  4.402521  3.0  5.0  7.0   8.0  30.0\n",
      "\n",
      "ðŸ”¤ Multi-word mechanics:\n",
      "  Total: 47\n",
      "  Examples:\n",
      "    - Living weapon (keyword_ability)\n",
      "    - Commander ninjutsu (keyword_ability)\n",
      "    - Legendary landwalk (keyword_ability)\n",
      "    - Nonbasic landwalk (keyword_ability)\n",
      "    - Level Up (keyword_ability)\n",
      "    - Double strike (keyword_ability)\n",
      "    - Cumulative upkeep (keyword_ability)\n",
      "    - First strike (keyword_ability)\n",
      "    - Aura Swap (keyword_ability)\n",
      "    - Battle Cry (keyword_ability)\n",
      "\n",
      "âž– Mechanics with hyphens:\n",
      "  Total: 2\n",
      "  Examples:\n",
      "    - Jump-start (keyword_ability)\n",
      "    - Web-slinging (keyword_ability)\n"
     ]
    }
   ],
   "source": [
    "# Combine all mechanics into one DataFrame for analysis\n",
    "all_mechanics = []\n",
    "\n",
    "if abilities_result['success']:\n",
    "    for ability in abilities_result['data']:\n",
    "        all_mechanics.append({\n",
    "            'mechanic': ability,\n",
    "            'category': 'keyword_ability',\n",
    "            'length': len(ability),\n",
    "            'has_space': ' ' in ability,\n",
    "            'has_hyphen': '-' in ability,\n",
    "            'word_count': len(ability.split())\n",
    "        })\n",
    "\n",
    "if actions_result['success']:\n",
    "    for action in actions_result['data']:\n",
    "        all_mechanics.append({\n",
    "            'mechanic': action,\n",
    "            'category': 'keyword_action',\n",
    "            'length': len(action),\n",
    "            'has_space': ' ' in action,\n",
    "            'has_hyphen': '-' in action,\n",
    "            'word_count': len(action.split())\n",
    "        })\n",
    "\n",
    "if ability_words_result['success']:\n",
    "    for word in ability_words_result['data']:\n",
    "        all_mechanics.append({\n",
    "            'mechanic': word,\n",
    "            'category': 'ability_word',\n",
    "            'length': len(word),\n",
    "            'has_space': ' ' in word,\n",
    "            'has_hyphen': '-' in word,\n",
    "            'word_count': len(word.split())\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(all_mechanics)\n",
    "\n",
    "print(\"ðŸ“Š DATA QUALITY ANALYSIS\")\n",
    "print(f\"\\nTotal mechanics: {len(df)}\")\n",
    "print(f\"\\nBreakdown by category:\")\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "print(f\"\\nðŸ“ String length statistics:\")\n",
    "print(df.groupby('category')['length'].describe())\n",
    "\n",
    "print(f\"\\nðŸ”¤ Multi-word mechanics:\")\n",
    "multi_word = df[df['word_count'] > 1]\n",
    "print(f\"  Total: {len(multi_word)}\")\n",
    "print(f\"  Examples:\")\n",
    "for _, row in multi_word.head(10).iterrows():\n",
    "    print(f\"    - {row['mechanic']} ({row['category']})\")\n",
    "\n",
    "print(f\"\\nâž– Mechanics with hyphens:\")\n",
    "hyphenated = df[df['has_hyphen']]\n",
    "print(f\"  Total: {len(hyphenated)}\")\n",
    "print(f\"  Examples:\")\n",
    "for _, row in hyphenated.head(10).iterrows():\n",
    "    print(f\"    - {row['mechanic']} ({row['category']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182a917",
   "metadata": {},
   "source": [
    "## Casing & Normalization Analysis\n",
    "\n",
    "Analyze casing patterns and check for duplicate mechanics using case-insensitive comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e35cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š CASING ANALYSIS\n",
      "\n",
      "ðŸ“ First 15 mechanics - casing patterns:\n",
      "          original          lowercase  is_capitalized\n",
      "     Living weapon      living weapon            True\n",
      "        Jump-start         jump-start            True\n",
      "Commander ninjutsu commander ninjutsu            True\n",
      "Legendary landwalk legendary landwalk            True\n",
      " Nonbasic landwalk  nonbasic landwalk            True\n",
      "         Megamorph          megamorph            True\n",
      "             Haunt              haunt            True\n",
      "          Forecast           forecast            True\n",
      "             Graft              graft            True\n",
      "           Fortify            fortify            True\n",
      "            Frenzy             frenzy            True\n",
      "        Gravestorm         gravestorm            True\n",
      "          Hideaway           hideaway            True\n",
      "          Level Up           level up            True\n",
      "            Infect             infect            True\n",
      "\n",
      "âœ… No duplicate mechanics found (case-insensitive)\n"
     ]
    }
   ],
   "source": [
    "# Check casing patterns\n",
    "print(\"ðŸ“Š CASING ANALYSIS\")\n",
    "\n",
    "casing_examples = []\n",
    "for mechanic in df['mechanic'].head(30):\n",
    "    casing_examples.append({\n",
    "        'original': mechanic,\n",
    "        'lowercase': mechanic.lower(),\n",
    "        'uppercase': mechanic.upper(),\n",
    "        'title_case': mechanic.title(),\n",
    "        'is_capitalized': mechanic[0].isupper() if mechanic else False\n",
    "    })\n",
    "\n",
    "casing_df = pd.DataFrame(casing_examples)\n",
    "print(\"\\nðŸ“ First 15 mechanics - casing patterns:\")\n",
    "print(casing_df[['original', 'lowercase', 'is_capitalized']].head(15).to_string(index=False))\n",
    "\n",
    "# Check for duplicate mechanics (case-insensitive)\n",
    "lowercase_mechanics = [m.lower() for m in df['mechanic']]\n",
    "duplicate_check = Counter(lowercase_mechanics)\n",
    "duplicates = {k: v for k, v in duplicate_check.items() if v > 1}\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"\\nâš ï¸ WARNING: Found {len(duplicates)} duplicate mechanics (case-insensitive):\")\n",
    "    for mech, count in duplicates.items():\n",
    "        print(f\"  - {mech}: appears {count} times\")\n",
    "else:\n",
    "    print(\"\\nâœ… No duplicate mechanics found (case-insensitive)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac901d7",
   "metadata": {},
   "source": [
    "## Search Pattern Testing\n",
    "\n",
    "Test mechanic detection against sample Magic oracle texts using lowercase string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf59a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” SEARCH PATTERN TESTING\n",
      "\n",
      "ðŸ“ Testing simple lowercase matching:\n",
      "\n",
      "  Text: Flying, deathtouch...\n",
      "  Found: Deathtouch, Flying\n",
      "\n",
      "  Text: Whenever you proliferate, draw a card....\n",
      "  Found: Proliferate\n",
      "\n",
      "  Text: Landfall â€” Whenever a land enters the battlefield under your...\n",
      "  Found: Create, Landfall\n",
      "\n",
      "  Text: Cycling {2}...\n",
      "  Found: Cycling\n",
      "\n",
      "  Text: Suspend 3â€”{1}{U}...\n",
      "  Found: Suspend\n",
      "\n",
      "  Text: Ninjutsu {U}...\n",
      "  Found: Ninjutsu\n",
      "\n",
      "  Text: This creature has flying and first strike....\n",
      "  Found: First strike, Flying\n",
      "\n",
      "  Text: Investigate. (Create a Clue token.)...\n",
      "  Found: Create, Investigate\n",
      "\n",
      "  Text: Battalion â€” Whenever this creature attacks with two or more ...\n",
      "  Found: Battalion\n"
     ]
    }
   ],
   "source": [
    "# Test how we would search for these mechanics in oracle text\n",
    "print(\"ðŸ” SEARCH PATTERN TESTING\")\n",
    "\n",
    "# Sample oracle texts to test against\n",
    "sample_oracle_texts = [\n",
    "    \"Flying, deathtouch\",\n",
    "    \"Whenever you proliferate, draw a card.\",\n",
    "    \"Landfall â€” Whenever a land enters the battlefield under your control, create a token.\",\n",
    "    \"Cycling {2}\",\n",
    "    \"Suspend 3â€”{1}{U}\",\n",
    "    \"Ninjutsu {U}\",\n",
    "    \"This creature has flying and first strike.\",\n",
    "    \"Investigate. (Create a Clue token.)\",\n",
    "    \"Battalion â€” Whenever this creature attacks with two or more other creatures, gain 3 life.\"\n",
    "]\n",
    "\n",
    "# Test simple lowercase matching\n",
    "print(\"\\nðŸ“ Testing simple lowercase matching:\")\n",
    "for text in sample_oracle_texts:\n",
    "    text_lower = text.lower()\n",
    "    found_mechanics = []\n",
    "    \n",
    "    for mechanic in df['mechanic']:\n",
    "        if mechanic.lower() in text_lower:\n",
    "            found_mechanics.append(mechanic)\n",
    "    \n",
    "    print(f\"\\n  Text: {text[:60]}...\")\n",
    "    if found_mechanics:\n",
    "        print(f\"  Found: {', '.join(found_mechanics)}\")\n",
    "    else:\n",
    "        print(f\"  Found: (none)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6983ea8",
   "metadata": {},
   "source": [
    "## Edge Cases & Special Patterns\n",
    "\n",
    "Identify and categorize edge cases: multi-word mechanics, very short mechanics, mechanics with numbers, and special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3cdaae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ EDGE CASES & SPECIAL PATTERNS\n",
      "\n",
      "1. Multi-word mechanics (potential matching issues):\n",
      "   Count: 47\n",
      "   Examples: ['Living weapon', 'Commander ninjutsu', 'Legendary landwalk', 'Nonbasic landwalk', 'Level Up', 'Double strike', 'Cumulative upkeep', 'First strike', 'Aura Swap', 'Battle Cry']\n",
      "\n",
      "2. Very short mechanics (false positive risk):\n",
      "   Count: 1\n",
      "   All: ['Tap']\n",
      "\n",
      "3. No mechanics with numbers found âœ…\n",
      "\n",
      "4. Mechanics with special characters:\n",
      "   Count: 5\n",
      "   All: ['For Mirrodin!', \"Doctor's companion\", \"Council's dilemma\", \"Hero's Reward\", 'Start your engines!']\n"
     ]
    }
   ],
   "source": [
    "# Identify edge cases\n",
    "print(\"âš ï¸ EDGE CASES & SPECIAL PATTERNS\")\n",
    "\n",
    "# Multi-word mechanics\n",
    "print(f\"\\n1. Multi-word mechanics (potential matching issues):\")\n",
    "multi_word_mechs = df[df['word_count'] > 1]['mechanic'].tolist()\n",
    "print(f\"   Count: {len(multi_word_mechs)}\")\n",
    "print(f\"   Examples: {multi_word_mechs[:10]}\")\n",
    "\n",
    "# Very short mechanics (2-3 chars - might cause false positives)\n",
    "short_mechs = df[df['length'] <= 3]['mechanic'].tolist()\n",
    "if short_mechs:\n",
    "    print(f\"\\n2. Very short mechanics (false positive risk):\")\n",
    "    print(f\"   Count: {len(short_mechs)}\")\n",
    "    print(f\"   All: {short_mechs}\")\n",
    "else:\n",
    "    print(f\"\\n2. No very short mechanics found âœ…\")\n",
    "\n",
    "# Mechanics with numbers\n",
    "mechs_with_numbers = df[df['mechanic'].str.contains(r'\\d', regex=True, na=False)]['mechanic'].tolist()\n",
    "if mechs_with_numbers:\n",
    "    print(f\"\\n3. Mechanics with numbers:\")\n",
    "    print(f\"   Count: {len(mechs_with_numbers)}\")\n",
    "    print(f\"   All: {mechs_with_numbers}\")\n",
    "else:\n",
    "    print(f\"\\n3. No mechanics with numbers found âœ…\")\n",
    "\n",
    "# Mechanics with special characters (beyond hyphen/space)\n",
    "special_char_pattern = r'[^a-zA-Z\\s\\-]'\n",
    "special_char_mechs = df[df['mechanic'].str.contains(special_char_pattern, regex=True, na=False)]['mechanic'].tolist()\n",
    "if special_char_mechs:\n",
    "    print(f\"\\n4. Mechanics with special characters:\")\n",
    "    print(f\"   Count: {len(special_char_mechs)}\")\n",
    "    print(f\"   All: {special_char_mechs}\")\n",
    "else:\n",
    "    print(f\"\\n4. No mechanics with special characters found âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7015e0",
   "metadata": {},
   "source": [
    "## Proposed MongoDB Schema Preview\n",
    "\n",
    "Display example normalized documents showing proposed MongoDB collection structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23e57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ PROPOSED MONGODB SCHEMA PREVIEW\n",
      "\n",
      "If we were to store this in MongoDB, the structure could be:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"living_weapon\",\n",
      "    \"name\": \"Living weapon\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"living weapon\",\n",
      "    \"word_count\": 2,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"jump_start\",\n",
      "    \"name\": \"Jump-start\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"jump-start\",\n",
      "    \"word_count\": 1,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"commander_ninjutsu\",\n",
      "    \"name\": \"Commander ninjutsu\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"commander ninjutsu\",\n",
      "    \"word_count\": 2,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"legendary_landwalk\",\n",
      "    \"name\": \"Legendary landwalk\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"legendary landwalk\",\n",
      "    \"word_count\": 2,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"nonbasic_landwalk\",\n",
      "    \"name\": \"Nonbasic landwalk\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"nonbasic landwalk\",\n",
      "    \"word_count\": 2,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"megamorph\",\n",
      "    \"name\": \"Megamorph\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"megamorph\",\n",
      "    \"word_count\": 1,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"haunt\",\n",
      "    \"name\": \"Haunt\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"haunt\",\n",
      "    \"word_count\": 1,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"forecast\",\n",
      "    \"name\": \"Forecast\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"forecast\",\n",
      "    \"word_count\": 1,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"graft\",\n",
      "    \"name\": \"Graft\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"graft\",\n",
      "    \"word_count\": 1,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"fortify\",\n",
      "    \"name\": \"Fortify\",\n",
      "    \"category\": \"keyword_ability\",\n",
      "    \"search_pattern\": \"fortify\",\n",
      "    \"word_count\": 1,\n",
      "    \"updated_at\": \"2026-01-22T00:00:00Z\"\n",
      "  }\n",
      "]\n",
      "\n",
      "ðŸ“ Collection name suggestion: 'mtg_mechanics'\n",
      "ðŸ“ Index suggestions:\n",
      "  - Unique index on 'id'\n",
      "  - Index on 'category' for filtering\n",
      "  - Text index on 'name' for search\n"
     ]
    }
   ],
   "source": [
    "# Show what the normalized data structure would look like\n",
    "print(\"ðŸ’¾ PROPOSED MONGODB SCHEMA PREVIEW\")\n",
    "print(\"\\nIf we were to store this in MongoDB, the structure could be:\")\n",
    "\n",
    "normalized_example = []\n",
    "for _, row in df.head(10).iterrows():\n",
    "    normalized_example.append({\n",
    "        'id': row['mechanic'].lower().replace(' ', '_').replace('-', '_'),\n",
    "        'name': row['mechanic'],\n",
    "        'category': row['category'],\n",
    "        'search_pattern': row['mechanic'].lower(),\n",
    "        'word_count': row['word_count'],\n",
    "        'updated_at': '2026-01-22T00:00:00Z'\n",
    "    })\n",
    "\n",
    "print(json.dumps(normalized_example, indent=2))\n",
    "\n",
    "print(\"\\nðŸ“ Collection name suggestion: 'mtg_mechanics'\")\n",
    "print(\"ðŸ“ Index suggestions:\")\n",
    "print(\"  - Unique index on 'id'\")\n",
    "print(\"  - Index on 'category' for filtering\")\n",
    "print(\"  - Text index on 'name' for search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b41c2",
   "metadata": {},
   "source": [
    "## Summary & Recommendations\n",
    "\n",
    "Generate comprehensive summary with API validation results, key findings, potential issues, and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2286fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“Š SUMMARY & RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "âœ… API VALIDATION:\n",
      "  - Keyword Abilities: 216\n",
      "  - Keyword Actions: 70\n",
      "  - Ability Words: 66\n",
      "  - Total Mechanics: 352\n",
      "\n",
      "ðŸ’¡ KEY FINDINGS:\n",
      "  1. All catalogs use consistent format (list of strings)\n",
      "  2. Casing: Capitalized\n",
      "  3. Multi-word mechanics: 47 found\n",
      "  4. Longest mechanic: 30 characters\n",
      "  5. Shortest mechanic: 3 characters\n",
      "\n",
      "ðŸš¨ POTENTIAL ISSUES:\n",
      "  - 47 multi-word mechanics require careful matching\n",
      "  - 1 very short mechanics may cause false positives\n",
      "\n",
      "ðŸ“‹ NEXT STEPS:\n",
      "  1. â¸ï¸  STOP HERE - Review findings with user\n",
      "  2. ðŸ—„ï¸  Design MongoDB schema based on validated structure\n",
      "  3. ðŸ”„ Plan integration with card scoring algorithm\n",
      "  4. ðŸ§ª Test mechanic detection on real card oracle text\n",
      "\n",
      "âœ… Exploration complete - awaiting user review\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ðŸ“Š SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nâœ… API VALIDATION:\")\n",
    "print(f\"  - Keyword Abilities: {len(abilities_result['data']) if abilities_result['success'] else 'FAILED'}\")\n",
    "print(f\"  - Keyword Actions: {len(actions_result['data']) if actions_result['success'] else 'FAILED'}\")\n",
    "print(f\"  - Ability Words: {len(ability_words_result['data']) if ability_words_result['success'] else 'FAILED'}\")\n",
    "print(f\"  - Total Mechanics: {len(df)}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ KEY FINDINGS:\")\n",
    "print(f\"  1. All catalogs use consistent format (list of strings)\")\n",
    "print(f\"  2. Casing: {'Capitalized' if df.iloc[0]['mechanic'][0].isupper() else 'Lowercase'}\")\n",
    "print(f\"  3. Multi-word mechanics: {len(df[df['word_count'] > 1])} found\")\n",
    "print(f\"  4. Longest mechanic: {df['length'].max()} characters\")\n",
    "print(f\"  5. Shortest mechanic: {df['length'].min()} characters\")\n",
    "\n",
    "print(f\"\\nðŸš¨ POTENTIAL ISSUES:\")\n",
    "issues = []\n",
    "\n",
    "if len(df[df['word_count'] > 1]) > 10:\n",
    "    issues.append(f\"  - {len(df[df['word_count'] > 1])} multi-word mechanics require careful matching\")\n",
    "\n",
    "if duplicates:\n",
    "    issues.append(f\"  - Found {len(duplicates)} case-sensitive duplicates\")\n",
    "\n",
    "if len(df[df['length'] <= 3]) > 0:\n",
    "    issues.append(f\"  - {len(df[df['length'] <= 3])} very short mechanics may cause false positives\")\n",
    "\n",
    "if issues:\n",
    "    for issue in issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"  âœ… No major issues detected\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ NEXT STEPS:\")\n",
    "print(f\"  1. â¸ï¸  STOP HERE - Review findings with user\")\n",
    "print(f\"  2. ðŸ—„ï¸  Design MongoDB schema based on validated structure\")\n",
    "print(f\"  3. ðŸ”„ Plan integration with card scoring algorithm\")\n",
    "print(f\"  4. ðŸ§ª Test mechanic detection on real card oracle text\")\n",
    "\n",
    "print(\"\\nâœ… Exploration complete - awaiting user review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d443500b",
   "metadata": {},
   "source": [
    "## Export Sample Data\n",
    "\n",
    "Export analysis results as CSV and complete API responses as JSON files to the notebooks folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb63a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample data exported:\n",
      "  - scryfall_mechanics_sample.csv\n",
      "  - scryfall_mechanics_full.json\n"
     ]
    }
   ],
   "source": [
    "# Export sample data for reference\n",
    "df.to_csv('/workspaces/mtgecorec/notebooks/scryfall_mechanics_sample.csv', index=False)\n",
    "\n",
    "# Export full lists as JSON\n",
    "export_data = {\n",
    "    'keyword_abilities': abilities_result['data'] if abilities_result['success'] else [],\n",
    "    'keyword_actions': actions_result['data'] if actions_result['success'] else [],\n",
    "    'ability_words': ability_words_result['data'] if ability_words_result['success'] else [],\n",
    "    'fetched_at': '2026-01-22T00:00:00Z',\n",
    "    'total_count': len(df)\n",
    "}\n",
    "\n",
    "with open('/workspaces/mtgecorec/notebooks/scryfall_mechanics_full.json', 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "print(\"âœ… Sample data exported:\")\n",
    "print(\"  - scryfall_mechanics_sample.csv\")\n",
    "print(\"  - scryfall_mechanics_full.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
